{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated Single Value Decomposition (tsvd) \n",
    "The TSVD algorithm is a linear dimensionality reduction algorithm which works really well for datasets in which samples correlated in large groups. TSVD does not center the data before computation unlike PCA. \n",
    "The TSVD model is implemented in the cuML library and can accept the following parameters: \n",
    "1. n_components : The number of top K singular vectors to be present in the output. The n_componnts variable must be <= number of columns.\n",
    "2. algorithm: selects the type of algorithm to be used: Jacobi or full. Jacobi is much faster as it iteratively corrects but is less accurate.\n",
    "3. n_iter: if the algorithm = 'Jacobi' then this variable decides the number of iterations. \n",
    "4. tol: if the algorithm = 'Jacobi' then this variable is used to set the tolerance\n",
    "5. random_state : select a random state if the results should be reproduceable across multiple runs.\n",
    "\n",
    "The functions that can be used with the tsvd:\n",
    "1. fit: fits the dataframe on the TSVD model\n",
    "2. fit_transform: fit the TSVD model on the dataset and perform dimensionality reduction\n",
    "3. transform: performs dimensionality reduction on the dataset\n",
    "4. inverse_transform: returns the original dataset from the dimensionally reduced one\n",
    "5. get_params: returns the value of the parameters set for the TSVD model\n",
    "6. set_params: allows the user to set the parameter of the TSVD model\n",
    "\n",
    "The model accepts only numpy arrays or cudf dataframes as the input. In order to convert your dataset to cudf format please read the cudf documentation on https://rapidsai.github.io/projects/cudf/en/latest/. For additional information on the tsvd model please refer to the documentation on https://rapidsai.github.io/projects/cuml/en/0.6.0/api.html#truncated-svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD as skTSVD\n",
    "from cuml import TruncatedSVD as cumlTSVD\n",
    "import cudf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the mortgage dataset is present and then extract the data from it, else throw an error statement\n",
    "import gzip\n",
    "# change the path of the mortgage dataset if you have saved it in a different directory\n",
    "def load_data(nrows, ncols, cached = 'data/mortgage.npy.gz'):\n",
    "    if os.path.exists(cached):\n",
    "        print('use mortgage data')\n",
    "        with gzip.open(cached) as f:\n",
    "            X = np.load(f)\n",
    "        X = X[np.random.randint(0,X.shape[0]-1,nrows),:ncols]\n",
    "    else:\n",
    "        # raise an exception if the dataset is not present\n",
    "        raise FileNotFoundError('Please download the required dataset or check the path')\n",
    "    df = pd.DataFrame({'fea%d'%i:X[:,i] for i in range(X.shape[1])})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function checks if the results obtained from two different libraries (sklearn and cuml) are the same\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def array_equal(a,b,threshold=5e-3,with_sign=True):\n",
    "    a = to_nparray(a)\n",
    "    b = to_nparray(b)\n",
    "    if with_sign == False:\n",
    "        a,b = np.abs(a),np.abs(b)\n",
    "    error = mean_squared_error(a,b)\n",
    "    res = error<threshold\n",
    "    return res\n",
    "\n",
    "# the function converts a variable from ndarray or dataframe format to numpy array\n",
    "def to_nparray(x):\n",
    "    if isinstance(x,np.ndarray) or isinstance(x,pd.DataFrame):\n",
    "        return np.array(x)\n",
    "    elif isinstance(x,np.float64):\n",
    "        return np.array([x])\n",
    "    elif isinstance(x,cudf.DataFrame) or isinstance(x,cudf.Series):\n",
    "        return x.to_pandas().values\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset and define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# nrows = number of samples\n",
    "# ncols = number of features of each sample\n",
    "\n",
    "nrows = 2**22\n",
    "ncols = 40\n",
    "\n",
    "X = load_data(nrows,ncols)\n",
    "print('data',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the value of some of the model parameters\n",
    "n_components = 10\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run sklearn tsvd on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# use the sklearn tsvd to reduce the dimentionality of the dataset\n",
    "algorithm='arpack'\n",
    "tsvd_sk = skTSVD(n_components=n_components,algorithm=algorithm, \n",
    "            random_state=random_state)\n",
    "# fits the dataset on the sklearn tsvd model and returns the dimensionally reduced dataset\n",
    "result_sk = tsvd_sk.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run cuml tsvd model on the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# convert pandas dataframe to cudf dataframe\n",
    "X = cudf.DataFrame.from_pandas(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# use the cuml tsvd model to reduce the dimentionality of the dataset\n",
    "algorithm='full'\n",
    "tsvd_cuml = cumlTSVD(n_components=n_components,algorithm=algorithm, \n",
    "            random_state=random_state)\n",
    "# fits the dataset on the cuml tsvd model and returns the dimensionally reduced dataset\n",
    "result_cuml = tsvd_cuml.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the value of the attributes obtained from the sklearn and cuml tsvd models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain attributes of the sklearn and cuml tsvd and check to see if they are equal\n",
    "for attr in ['singular_values_','components_']:\n",
    "    passed = array_equal(getattr(tsvd_sk,attr),getattr(tsvd_cuml,attr),threshold=0.1)\n",
    "    # larger error margin due to different algorithms: arpack vs full\n",
    "    message = 'compare tsvd: cuml vs sklearn {:>25} {}'.format(attr,'equal' if passed else 'NOT equal')\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the reduced matrix\n",
    "passed = array_equal(result_sk,result_cuml,threshold=0.1)\n",
    "# larger error margin due to different algorithms: arpack vs full\n",
    "message = 'compare tsvd: cuml vs sklearn transformed results %s'%('equal'if passed else 'NOT equal')\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
